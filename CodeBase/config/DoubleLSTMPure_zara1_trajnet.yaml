experiment_name: 'doublelstmPure_zara1_trajnet' 
device: 'cpu'

# MODEL
model:
  name: 'doubleLSTMPure'
  pretrain: ''
  save_name: 'doublelstmPure_zara1'
  kwargs:
    inp_size: 2 
    out_size: 3
    num_layers: 3
    hidden_size: 128
    
    # obs_len: 8
    # pred_len: 12  # in timesteps
    

  # loss
  loss_function: 
    name: 'pairwise_distance_loss'
    kwargs: {}
      # loss_scale: 1000  # factor to scale the loss
#dataset

dataset:
  name: 'zara1' # imageTraj or trajectory(not support)
  dataset_name: 'traj_dataset'
  num_goals: 1  # K_e
  num_traj: 1  # K_a
  train_data_path: '../dataset/zara1/train'
  train_image_path: ''
  val_data_path: '../dataset/zara1/test'
  val_image_path: ''
  test_data_path: '../dataset/zara1/test'
  test_image_path: ''

  # data info
  resize: 1.0
  batch_size: 100
  obs_len: 8
  pred_len: 12
  num_workers: 4 
  prefetch_factor: 2
  # load_to_gpu: True
  # Ynet
  division_factor: 32 # use in Ynet the division factor must be 2^(len(encoder_channels))
  kernlen: 31  # (image) size of Gaussian kernel used for ground-truth Gaussian heatmap
  nsig: 4  # sigma of Gaussian kernel used for ground-truth Gaussian heatmap
  waypoints: ''
  # For semantic map
  segmentation_model_fp: ''
  semantic_classes: ''
  use_features_only: False  # If True the segmentation model only uses the

  #Sampler
  sampler: 
    name: 'custom' # custom or interval
    trainkwargs: {}
      # num_interval: 25 # for one epoch, the max num_interval for sampling
    valkwargs: {}
      # num_interval: 9999999 # for one epoch, the max num_interval for sampling
  collate_name: 'traj_collate'

optim:
  name: 'Noam'
  kwargs:
    emb_size: 128
    factor: 1.0
    warmup: 10
    lr: 0.0
  # learning_rate: 0.0001
  num_epochs: 150

# TEST

test:
  # TTST
  use_TTST: False
  rel_threshold: 0.01
  # CWS
  use_CWS: False
  CWS_params: None

  eval_step: 10
  temperature: 1.0
  round: 1

unfreeze: 150  # Unfreeze semantic segmentation model weights after this # of epochs
viz_epoch: 10
extra_info_name: 'datasetMeanStd'